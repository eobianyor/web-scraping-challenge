{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PyMongo to work with MongoDBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define database and collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=client.Mars_NewsDB\n",
    "News_collection=db.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL of page to be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve page with the requests module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "NASA_Gov_News = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BeautifulSoup object using the response text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(NASA_Gov_News.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the div tags for all articles in a variable called results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# results = soup.select_one(\"ul.item_list li.slide\")\n",
    "# print(results)\n",
    "# news_title = results.find('div', class_='content_title').text\n",
    "# news_para = results.find('div', class_='article_teaser_body').text\n",
    "\n",
    "\n",
    "results2 = soup.body.find_all(\"ul.item_list li.slide\")\n",
    "print(results2)\n",
    "# # results2 = soup.find_all('div', class_='list_text')\n",
    "# # results2 = soup.find_all('div', class_='list_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(results1.prettify())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for news_header in results1:\n",
    "    try:\n",
    "        news_title = news_header.find['href'].text\n",
    "\n",
    "        print(\"====================\")\n",
    "        print(news_title)\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "#         continue\n",
    "# news_title = news_header.find('a', 'div', class_='content_title')['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Structure of what my scrape.py should look like\n",
    "# def scrape_everthing():\n",
    "#     title,para = scrape_title()\n",
    "#     data = {\n",
    "#         'title': title\n",
    "#         'para': para\n",
    "#         'freatured_imgs': feature_img()\n",
    "#     }\n",
    "#     return data\n",
    "\n",
    "# def scrape_title():\n",
    "    \n",
    "#     return title, para\n",
    "\n",
    "# def feature_img():\n",
    "    \n",
    "#     return img_url\n",
    "\n",
    "\n",
    "# # Structure of what my app.py should look like\n",
    "\n",
    "# from scrape import scrape_everthing\n",
    "\n",
    "# @app.route('/scrape')\n",
    "# data = scrape_everthing()\n",
    "# mars.update(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Steps to complete challenge\n",
    "# ipynb note book -> scaping tutorial - Just to perfect your web-scrapping code then you'll transfer it to scrape.py\n",
    "\n",
    "# scrape.py -> Run all your web scrapping here and put all your returns into one dictionary. See above cell. \n",
    "#             This will be one instance of this so no loops necessary other than for the hemispheres pics\n",
    "\n",
    "# Set up mongodb, create a db, create a collection called mars\n",
    "\n",
    "# app.py -> flask route defined, calling for the one func() from scrape.py update your mongodb collection (mars.update())\n",
    "#           render_template index.html -> mars\n",
    "\n",
    "# index.html -> You set it up with things like {{ news.title }} to pull in from app.py? Mongodb? You will need to set up for loop for hemisphere stuff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
